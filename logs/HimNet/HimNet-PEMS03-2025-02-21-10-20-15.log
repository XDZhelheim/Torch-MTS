PEMS03
Trainset:	x-(15711, 12, 358, 3)	y-(15711, 12, 358, 3)
Valset:  	x-(5237, 12, 358, 3)  	y-(5237, 12, 358, 3)
Testset:	x-(5237, 12, 358, 3)	y-(5237, 12, 358, 3)

Random seed = 233
--------- HimNet ---------
{
    "num_nodes": 358,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "day_of_week": true,
    "y_time_of_day": true,
    "y_day_of_week": true,
    "runner": "himnet",
    "lr": 0.001,
    "eps": 0.001,
    "weight_decay": 0.0003,
    "milestones": [
        30,
        50
    ],
    "clip_grad": 5,
    "batch_size": 16,
    "max_epochs": 200,
    "early_stop": 20,
    "model_args": {
        "num_nodes": 358,
        "input_dim": 3,
        "output_dim": 1,
        "tod_embedding_dim": 8,
        "dow_embedding_dim": 8,
        "out_steps": 12,
        "hidden_dim": 64,
        "num_layers": 1,
        "cheb_k": 2,
        "ycov_dim": 2,
        "node_embedding_dim": 16,
        "st_embedding_dim": 16,
        "tf_decay_steps": 4000,
        "use_teacher_forcing": true
    }
}
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
HimNet                                   [16, 12, 358, 1]          5,728
├─Embedding: 1-1                         [16, 8]                   2,304
├─Embedding: 1-2                         [16, 8]                   56
├─HimEncoder: 1-3                        [16, 12, 358, 64]         --
│    └─ModuleList: 2-1                   --                        --
│    │    └─HimGCRU: 3-1                 [16, 358, 64]             414,720
│    │    └─HimGCRU: 3-2                 [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-3                 [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-4                 [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-5                 [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-6                 [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-7                 [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-8                 [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-9                 [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-10                [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-11                [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-12                [16, 358, 64]             (recursive)
├─HimEncoder: 1-4                        [16, 12, 358, 64]         --
│    └─ModuleList: 2-2                   --                        --
│    │    └─HimGCRU: 3-13                [16, 358, 64]             414,720
│    │    └─HimGCRU: 3-14                [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-15                [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-16                [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-17                [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-18                [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-19                [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-20                [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-21                [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-22                [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-23                [16, 358, 64]             (recursive)
│    │    └─HimGCRU: 3-24                [16, 358, 64]             (recursive)
├─Linear: 1-5                            [16, 358, 16]             1,040
├─HimDecoder: 1-6                        [16, 358, 64]             --
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-25                [16, 358, 64]             414,720
├─Linear: 1-7                            [16, 358, 1]              65
├─HimDecoder: 1-8                        [16, 358, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-26                [16, 358, 64]             (recursive)
├─Linear: 1-9                            [16, 358, 1]              (recursive)
├─HimDecoder: 1-10                       [16, 358, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-27                [16, 358, 64]             (recursive)
├─Linear: 1-11                           [16, 358, 1]              (recursive)
├─HimDecoder: 1-12                       [16, 358, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-28                [16, 358, 64]             (recursive)
├─Linear: 1-13                           [16, 358, 1]              (recursive)
├─HimDecoder: 1-14                       [16, 358, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-29                [16, 358, 64]             (recursive)
├─Linear: 1-15                           [16, 358, 1]              (recursive)
├─HimDecoder: 1-16                       [16, 358, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-30                [16, 358, 64]             (recursive)
├─Linear: 1-17                           [16, 358, 1]              (recursive)
├─HimDecoder: 1-18                       [16, 358, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-31                [16, 358, 64]             (recursive)
├─Linear: 1-19                           [16, 358, 1]              (recursive)
├─HimDecoder: 1-20                       [16, 358, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-32                [16, 358, 64]             (recursive)
├─Linear: 1-21                           [16, 358, 1]              (recursive)
├─HimDecoder: 1-22                       [16, 358, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-33                [16, 358, 64]             (recursive)
├─Linear: 1-23                           [16, 358, 1]              (recursive)
├─HimDecoder: 1-24                       [16, 358, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-34                [16, 358, 64]             (recursive)
├─Linear: 1-25                           [16, 358, 1]              (recursive)
├─HimDecoder: 1-26                       [16, 358, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-35                [16, 358, 64]             (recursive)
├─Linear: 1-27                           [16, 358, 1]              (recursive)
├─HimDecoder: 1-28                       [16, 358, 64]             (recursive)
│    └─ModuleList: 2-14                  --                        (recursive)
│    │    └─HimGCRU: 3-36                [16, 358, 64]             (recursive)
├─Linear: 1-29                           [16, 358, 1]              (recursive)
==========================================================================================
Total params: 1,253,353
Trainable params: 1,253,353
Non-trainable params: 0
Total mult-adds (G): 85.52
==========================================================================================
Input size (MB): 1.37
Forward/backward pass size (MB): 318.02
Params size (MB): 4.99
Estimated Total Size (MB): 324.39
==========================================================================================

Loss: HuberLoss

2025-02-21 10:24:51.944230 Epoch 1  	Train Loss = 17.06683 Val Loss = 23.88211
2025-02-21 10:29:14.306545 Epoch 2  	Train Loss = 13.31148 Val Loss = 21.15961
2025-02-21 10:33:53.388754 Epoch 3  	Train Loss = 13.00984 Val Loss = 20.01298
2025-02-21 10:38:40.106525 Epoch 4  	Train Loss = 12.73138 Val Loss = 19.08059
2025-02-21 10:43:24.689227 Epoch 5  	Train Loss = 12.48691 Val Loss = 22.75887
2025-02-21 10:48:08.005127 Epoch 6  	Train Loss = 12.18931 Val Loss = 17.14742
2025-02-21 10:52:51.405840 Epoch 7  	Train Loss = 11.89730 Val Loss = 18.05877
2025-02-21 10:57:33.394093 Epoch 8  	Train Loss = 11.68087 Val Loss = 16.86770
2025-02-21 11:02:17.637389 Epoch 9  	Train Loss = 11.48011 Val Loss = 15.72372
2025-02-21 11:07:03.221308 Epoch 10  	Train Loss = 11.34574 Val Loss = 15.46592
2025-02-21 11:11:41.169423 Epoch 11  	Train Loss = 11.21426 Val Loss = 15.07080
2025-02-21 11:16:22.716478 Epoch 12  	Train Loss = 11.11822 Val Loss = 15.23678
2025-02-21 11:21:11.173091 Epoch 13  	Train Loss = 11.03841 Val Loss = 15.02832
2025-02-21 11:25:57.571199 Epoch 14  	Train Loss = 11.00568 Val Loss = 15.04101
2025-02-21 11:30:43.077401 Epoch 15  	Train Loss = 10.93415 Val Loss = 14.09893
2025-02-21 11:35:31.389044 Epoch 16  	Train Loss = 10.87213 Val Loss = 14.65502
2025-02-21 11:40:17.014191 Epoch 17  	Train Loss = 10.84233 Val Loss = 14.36280
2025-02-21 11:45:03.892147 Epoch 18  	Train Loss = 10.81077 Val Loss = 14.49642
2025-02-21 11:49:44.947035 Epoch 19  	Train Loss = 10.78896 Val Loss = 14.19426
2025-02-21 11:54:29.596367 Epoch 20  	Train Loss = 10.75772 Val Loss = 13.99863
2025-02-21 11:59:04.501600 Epoch 21  	Train Loss = 10.73973 Val Loss = 14.32491
2025-02-21 12:03:39.335188 Epoch 22  	Train Loss = 10.74186 Val Loss = 14.11182
2025-02-21 12:08:09.602027 Epoch 23  	Train Loss = 10.74282 Val Loss = 14.20037
2025-02-21 12:12:42.390891 Epoch 24  	Train Loss = 10.73468 Val Loss = 14.53740
2025-02-21 12:17:16.635408 Epoch 25  	Train Loss = 10.75518 Val Loss = 14.46790
2025-02-21 12:21:52.918245 Epoch 26  	Train Loss = 10.77893 Val Loss = 14.86241
2025-02-21 12:26:32.515868 Epoch 27  	Train Loss = 10.81262 Val Loss = 14.12858
2025-02-21 12:31:07.022340 Epoch 28  	Train Loss = 10.86450 Val Loss = 14.11194
2025-02-21 12:35:41.129129 Epoch 29  	Train Loss = 10.93092 Val Loss = 14.16273
2025-02-21 12:40:24.006217 Epoch 30  	Train Loss = 11.01146 Val Loss = 13.91741
2025-02-21 12:44:57.110885 Epoch 31  	Train Loss = 10.69043 Val Loss = 13.04508
2025-02-21 12:49:41.749855 Epoch 32  	Train Loss = 10.70279 Val Loss = 13.00998
2025-02-21 12:54:25.562810 Epoch 33  	Train Loss = 10.76461 Val Loss = 12.97972
2025-02-21 12:59:07.613375 Epoch 34  	Train Loss = 10.84894 Val Loss = 12.96571
2025-02-21 13:03:51.452375 Epoch 35  	Train Loss = 10.94846 Val Loss = 13.00417
2025-02-21 13:08:30.710249 Epoch 36  	Train Loss = 11.04967 Val Loss = 13.02355
2025-02-21 13:13:06.762910 Epoch 37  	Train Loss = 11.13682 Val Loss = 12.94493
2025-02-21 13:17:48.478182 Epoch 38  	Train Loss = 11.23325 Val Loss = 12.98959
2025-02-21 13:22:04.479816 Epoch 39  	Train Loss = 11.32457 Val Loss = 13.02675
2025-02-21 13:26:48.021067 Epoch 40  	Train Loss = 11.39744 Val Loss = 13.01738
2025-02-21 13:31:28.713432 Epoch 41  	Train Loss = 11.49290 Val Loss = 12.92901
2025-02-21 13:36:07.498065 Epoch 42  	Train Loss = 11.54759 Val Loss = 12.92005
2025-02-21 13:40:46.948329 Epoch 43  	Train Loss = 11.60080 Val Loss = 12.89161
2025-02-21 13:45:25.780541 Epoch 44  	Train Loss = 11.64336 Val Loss = 12.93017
2025-02-21 13:50:01.641413 Epoch 45  	Train Loss = 11.67537 Val Loss = 12.93822
2025-02-21 13:54:37.932694 Epoch 46  	Train Loss = 11.72484 Val Loss = 13.00208
2025-02-21 13:59:11.873755 Epoch 47  	Train Loss = 11.74173 Val Loss = 13.00417
2025-02-21 14:03:44.111393 Epoch 48  	Train Loss = 11.75555 Val Loss = 12.90304
2025-02-21 14:08:21.375463 Epoch 49  	Train Loss = 11.77033 Val Loss = 13.02788
2025-02-21 14:12:54.893376 Epoch 50  	Train Loss = 11.77188 Val Loss = 13.04965
2025-02-21 14:17:31.028798 Epoch 51  	Train Loss = 11.64058 Val Loss = 12.86271
2025-02-21 14:22:10.035185 Epoch 52  	Train Loss = 11.63169 Val Loss = 12.84897
2025-02-21 14:26:42.055880 Epoch 53  	Train Loss = 11.63574 Val Loss = 12.85639
2025-02-21 14:31:03.361145 Epoch 54  	Train Loss = 11.63453 Val Loss = 12.88269
2025-02-21 14:35:32.788573 Epoch 55  	Train Loss = 11.63499 Val Loss = 12.84523
2025-02-21 14:40:09.169066 Epoch 56  	Train Loss = 11.63755 Val Loss = 12.85882
2025-02-21 14:44:46.760683 Epoch 57  	Train Loss = 11.63530 Val Loss = 12.89647
2025-02-21 14:49:26.945860 Epoch 58  	Train Loss = 11.63433 Val Loss = 12.84874
2025-02-21 14:54:09.925537 Epoch 59  	Train Loss = 11.63172 Val Loss = 12.84342
2025-02-21 14:58:42.952556 Epoch 60  	Train Loss = 11.63234 Val Loss = 12.85609
2025-02-21 15:03:14.695367 Epoch 61  	Train Loss = 11.62887 Val Loss = 12.86742
2025-02-21 15:07:45.780956 Epoch 62  	Train Loss = 11.62753 Val Loss = 12.85863
2025-02-21 15:12:14.607948 Epoch 63  	Train Loss = 11.62679 Val Loss = 12.87710
2025-02-21 15:16:28.553825 Epoch 64  	Train Loss = 11.62385 Val Loss = 12.85583
2025-02-21 15:21:02.018977 Epoch 65  	Train Loss = 11.62413 Val Loss = 12.85450
2025-02-21 15:25:35.499259 Epoch 66  	Train Loss = 11.62112 Val Loss = 12.85249
2025-02-21 15:30:06.175023 Epoch 67  	Train Loss = 11.61923 Val Loss = 12.90876
2025-02-21 15:34:38.722255 Epoch 68  	Train Loss = 11.61772 Val Loss = 12.88882
2025-02-21 15:39:15.270596 Epoch 69  	Train Loss = 11.61556 Val Loss = 12.87557
2025-02-21 15:43:50.629114 Epoch 70  	Train Loss = 11.61396 Val Loss = 12.88667
2025-02-21 15:48:25.409672 Epoch 71  	Train Loss = 11.61217 Val Loss = 12.87581
2025-02-21 15:53:01.181444 Epoch 72  	Train Loss = 11.61068 Val Loss = 12.85144
2025-02-21 15:57:37.199689 Epoch 73  	Train Loss = 11.60818 Val Loss = 12.90686
2025-02-21 16:02:08.538792 Epoch 74  	Train Loss = 11.60623 Val Loss = 12.85841
2025-02-21 16:06:39.292396 Epoch 75  	Train Loss = 11.60526 Val Loss = 12.86613
2025-02-21 16:11:10.253982 Epoch 76  	Train Loss = 11.60301 Val Loss = 12.88918
2025-02-21 16:15:44.063372 Epoch 77  	Train Loss = 11.60094 Val Loss = 12.87427
2025-02-21 16:20:15.937058 Epoch 78  	Train Loss = 11.59947 Val Loss = 12.89677
2025-02-21 16:24:52.384308 Epoch 79  	Train Loss = 11.59759 Val Loss = 12.89125
Early stopping at epoch: 79
Best at epoch 59:
Train Loss = 11.63172
Train MAE = 12.14424, RMSE = 20.05735, MAPE = 11.34073
Val Loss = 12.84342
Val MAE = 13.35366, RMSE = 21.77654, MAPE = 12.74728
Model checkpoint saved to: ../saved_models/HimNet/HimNet-PEMS03-2025-02-21-10-20-15.pt
--------- Test ---------
All Steps (1-12) MAE = 15.34438, RMSE = 27.50245, MAPE = 15.82208
Step 1 MAE = 11.75395, RMSE = 20.48409, MAPE = 12.67687
Step 2 MAE = 13.09553, RMSE = 23.10713, MAPE = 13.88043
Step 3 MAE = 13.85725, RMSE = 24.70782, MAPE = 14.63220
Step 4 MAE = 14.45801, RMSE = 25.93747, MAPE = 15.07307
Step 5 MAE = 14.97294, RMSE = 26.89467, MAPE = 15.47598
Step 6 MAE = 15.42897, RMSE = 27.67894, MAPE = 15.86180
Step 7 MAE = 15.85366, RMSE = 28.36380, MAPE = 16.23032
Step 8 MAE = 16.24264, RMSE = 28.96654, MAPE = 16.56417
Step 9 MAE = 16.60526, RMSE = 29.55584, MAPE = 16.88896
Step 10 MAE = 16.95171, RMSE = 30.14676, MAPE = 17.20255
Step 11 MAE = 17.28839, RMSE = 30.72899, MAPE = 17.52322
Step 12 MAE = 17.62414, RMSE = 31.30801, MAPE = 17.85519
Inference time: 38.53 s

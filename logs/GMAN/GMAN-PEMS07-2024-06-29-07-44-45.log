PEMS07
Trainset:	x-(16921, 12, 883, 3)	y-(16921, 12, 883, 3)
Valset:  	x-(5640, 12, 883, 3)  	y-(5640, 12, 883, 3)
Testset:	x-(5640, 12, 883, 3)	y-(5640, 12, 883, 3)

Random seed = 233
--------- GMAN ---------
{
    "num_nodes": 883,
    "in_steps": 12,
    "out_steps": 12,
    "pass_device": true,
    "time_of_day": true,
    "day_of_week": true,
    "y_time_of_day": true,
    "y_day_of_week": true,
    "runner": "gman",
    "lr": 0.001,
    "weight_decay": 0.0001,
    "milestones": [
        10,
        15
    ],
    "clip_grad": 5,
    "batch_size": 16,
    "max_epochs": 200,
    "early_stop": 20,
    "model_args": {
        "SE_file_path": "../data/PEMS07/SE_PEMS07.txt",
        "timestep_in": 12,
        "statt_layers": 1,
        "att_heads": 8,
        "att_dims": 8,
        "bn_decay": 0.1,
        "device": "cuda:0"
    }
}
=========================================================================================================
Layer (type:depth-idx)                                  Output Shape              Param #
=========================================================================================================
GMAN                                                    [16, 12, 883, 1]          --
├─FC: 1-1                                               [16, 12, 883, 64]         --
│    └─ModuleList: 2-1                                  --                        --
│    │    └─conv2d_: 3-1                                [16, 12, 883, 64]         256
│    │    └─conv2d_: 3-2                                [16, 12, 883, 64]         4,288
├─STEmbedding: 1-2                                      [16, 24, 883, 64]         --
│    └─FC: 2-2                                          [1, 1, 883, 64]           --
│    │    └─ModuleList: 3-3                             --                        8,576
│    └─FC: 2-3                                          [16, 24, 1, 64]           --
│    │    └─ModuleList: 3-4                             --                        23,360
├─ModuleList: 1-3                                       --                        --
│    └─STAttBlock: 2-4                                  [16, 12, 883, 64]         --
│    │    └─spatialAttention: 3-5                       [16, 12, 883, 64]         29,440
│    │    └─temporalAttention: 3-6                      [16, 12, 883, 64]         29,440
│    │    └─gatedFusion: 3-7                            [16, 12, 883, 64]         17,088
├─transformAttention: 1-4                               [16, 12, 883, 64]         --
│    └─FC: 2-5                                          [16, 12, 883, 64]         --
│    │    └─ModuleList: 3-8                             --                        4,288
│    └─FC: 2-6                                          [16, 12, 883, 64]         --
│    │    └─ModuleList: 3-9                             --                        4,288
│    └─FC: 2-7                                          [16, 12, 883, 64]         --
│    │    └─ModuleList: 3-10                            --                        4,288
│    └─FC: 2-8                                          [16, 12, 883, 64]         --
│    │    └─ModuleList: 3-11                            --                        4,288
├─ModuleList: 1-5                                       --                        --
│    └─STAttBlock: 2-9                                  [16, 12, 883, 64]         --
│    │    └─spatialAttention: 3-12                      [16, 12, 883, 64]         29,440
│    │    └─temporalAttention: 3-13                     [16, 12, 883, 64]         29,440
│    │    └─gatedFusion: 3-14                           [16, 12, 883, 64]         17,088
├─FC: 1-6                                               [16, 12, 883, 1]          --
│    └─ModuleList: 2-10                                 --                        --
│    │    └─conv2d_: 3-15                               [16, 12, 883, 64]         4,288
│    │    └─conv2d_: 3-16                               [16, 12, 883, 1]          67
=========================================================================================================
Total params: 209,923
Trainable params: 209,923
Non-trainable params: 0
Total mult-adds (G): 29.52
=========================================================================================================
Input size (MB): 3.39
Forward/backward pass size (MB): 5387.06
Params size (MB): 0.84
Estimated Total Size (MB): 5391.29
=========================================================================================================

Loss: HuberLoss

2024-06-29 07:54:30.525354 Epoch 1  	Train Loss = 42.54394 Val Loss = 25.48855
2024-06-29 08:04:08.024378 Epoch 2  	Train Loss = 38.03129 Val Loss = 26.22548
2024-06-29 08:13:45.441232 Epoch 3  	Train Loss = 36.82132 Val Loss = 24.56177
2024-06-29 08:23:22.608117 Epoch 4  	Train Loss = 36.92103 Val Loss = 23.11212
2024-06-29 08:32:59.981342 Epoch 5  	Train Loss = 35.99734 Val Loss = 22.19466
2024-06-29 08:42:37.359603 Epoch 6  	Train Loss = 36.86875 Val Loss = 23.44861
2024-06-29 08:52:14.639332 Epoch 7  	Train Loss = 36.51647 Val Loss = 21.69703
2024-06-29 09:01:51.783888 Epoch 8  	Train Loss = 36.21649 Val Loss = 24.44455
2024-06-29 09:11:28.694631 Epoch 9  	Train Loss = 35.11798 Val Loss = 22.61626
2024-06-29 09:21:05.931926 Epoch 10  	Train Loss = 34.91227 Val Loss = 23.23906
2024-06-29 09:30:43.166845 Epoch 11  	Train Loss = 34.26208 Val Loss = 20.66440
2024-06-29 09:40:20.434895 Epoch 12  	Train Loss = 34.42109 Val Loss = 24.01224
2024-06-29 09:49:57.605397 Epoch 13  	Train Loss = 34.58854 Val Loss = 22.45555
2024-06-29 09:59:34.774292 Epoch 14  	Train Loss = 34.04514 Val Loss = 20.48300
2024-06-29 10:09:11.916148 Epoch 15  	Train Loss = 35.36712 Val Loss = 23.53552
2024-06-29 10:18:48.974673 Epoch 16  	Train Loss = 34.70267 Val Loss = 20.53543
2024-06-29 10:28:26.194406 Epoch 17  	Train Loss = 34.22061 Val Loss = 20.31043
2024-06-29 10:38:03.388273 Epoch 18  	Train Loss = 35.54995 Val Loss = 22.85671
2024-06-29 10:47:40.241085 Epoch 19  	Train Loss = 34.32419 Val Loss = 20.31405
2024-06-29 10:57:17.599226 Epoch 20  	Train Loss = 34.86076 Val Loss = 23.99964
2024-06-29 11:06:55.169560 Epoch 21  	Train Loss = 34.14678 Val Loss = 20.16338
2024-06-29 11:16:32.626261 Epoch 22  	Train Loss = 34.46619 Val Loss = 21.15469
2024-06-29 11:26:09.976415 Epoch 23  	Train Loss = 34.25916 Val Loss = 20.61539
2024-06-29 11:35:47.295126 Epoch 24  	Train Loss = 34.24307 Val Loss = 24.95862
2024-06-29 11:45:24.623029 Epoch 25  	Train Loss = 34.35623 Val Loss = 21.24978
2024-06-29 11:55:01.925094 Epoch 26  	Train Loss = 34.27702 Val Loss = 21.20287
2024-06-29 12:04:39.315527 Epoch 27  	Train Loss = 33.54442 Val Loss = 20.48595
2024-06-29 12:14:16.743012 Epoch 28  	Train Loss = 34.72855 Val Loss = 21.32364
2024-06-29 12:23:53.877704 Epoch 29  	Train Loss = 35.04102 Val Loss = 22.08823
2024-06-29 12:33:31.042719 Epoch 30  	Train Loss = 35.11772 Val Loss = 21.15156
2024-06-29 12:43:08.300754 Epoch 31  	Train Loss = 34.73734 Val Loss = 20.64237
2024-06-29 12:52:45.578114 Epoch 32  	Train Loss = 34.17625 Val Loss = 22.78883
2024-06-29 13:02:22.691911 Epoch 33  	Train Loss = 34.48120 Val Loss = 20.20729
2024-06-29 13:11:59.948503 Epoch 34  	Train Loss = 33.71725 Val Loss = 20.15837
2024-06-29 13:21:37.296695 Epoch 35  	Train Loss = 33.69591 Val Loss = 21.11675
2024-06-29 13:31:14.445391 Epoch 36  	Train Loss = 33.83728 Val Loss = 20.03402
2024-06-29 13:40:51.543983 Epoch 37  	Train Loss = 34.17660 Val Loss = 21.68207
2024-06-29 13:50:28.743620 Epoch 38  	Train Loss = 34.03544 Val Loss = 22.83157
2024-06-29 14:00:05.952971 Epoch 39  	Train Loss = 34.32946 Val Loss = 21.05902
2024-06-29 14:09:43.103363 Epoch 40  	Train Loss = 34.30185 Val Loss = 23.63822
2024-06-29 14:19:20.263498 Epoch 41  	Train Loss = 34.64254 Val Loss = 20.46906
2024-06-29 14:28:57.481286 Epoch 42  	Train Loss = 34.32532 Val Loss = 23.31713
2024-06-29 14:38:34.581638 Epoch 43  	Train Loss = 33.97097 Val Loss = 24.97733
2024-06-29 14:48:11.892473 Epoch 44  	Train Loss = 34.24616 Val Loss = 25.65778
2024-06-29 14:57:49.199069 Epoch 45  	Train Loss = 33.69941 Val Loss = 20.10253
2024-06-29 15:07:26.486950 Epoch 46  	Train Loss = 35.19255 Val Loss = 23.09625
2024-06-29 15:17:03.763945 Epoch 47  	Train Loss = 34.24227 Val Loss = 24.35915
2024-06-29 15:26:40.832162 Epoch 48  	Train Loss = 33.57997 Val Loss = 20.66554
2024-06-29 15:36:17.952045 Epoch 49  	Train Loss = 34.73323 Val Loss = 21.25160
2024-06-29 15:45:55.038237 Epoch 50  	Train Loss = 34.06672 Val Loss = 20.89737
2024-06-29 15:55:32.067975 Epoch 51  	Train Loss = 34.72425 Val Loss = 24.78311
2024-06-29 16:05:09.219559 Epoch 52  	Train Loss = 33.99762 Val Loss = 25.09723
2024-06-29 16:14:46.279185 Epoch 53  	Train Loss = 33.99497 Val Loss = 20.51586
2024-06-29 16:24:23.423452 Epoch 54  	Train Loss = 35.06853 Val Loss = 20.65152
2024-06-29 16:34:00.646304 Epoch 55  	Train Loss = 34.36481 Val Loss = 25.12900
2024-06-29 16:43:37.883838 Epoch 56  	Train Loss = 34.40585 Val Loss = 20.43515
Early stopping at epoch: 56
Best at epoch 36:
Train Loss = 33.83728
Train MAE = 19.72594, RMSE = 32.41625, MAPE = 9.17784
Val Loss = 20.03402
Val MAE = 20.56692, RMSE = 33.65772, MAPE = 9.55890
Model checkpoint saved to: ../saved_models/GMAN/GMAN-PEMS07-2024-06-29-07-44-45.pt
--------- Test ---------
All Steps (1-12) MAE = 20.56382, RMSE = 33.51183, MAPE = 9.14369
Step 1 MAE = 18.38228, RMSE = 29.25136, MAPE = 8.14388
Step 2 MAE = 18.84074, RMSE = 30.35172, MAPE = 8.32354
Step 3 MAE = 19.27613, RMSE = 31.23943, MAPE = 8.50823
Step 4 MAE = 19.67484, RMSE = 32.00714, MAPE = 8.67677
Step 5 MAE = 20.04510, RMSE = 32.70194, MAPE = 8.84454
Step 6 MAE = 20.41895, RMSE = 33.36122, MAPE = 9.02501
Step 7 MAE = 20.78679, RMSE = 33.97930, MAPE = 9.20745
Step 8 MAE = 21.14568, RMSE = 34.56907, MAPE = 9.39228
Step 9 MAE = 21.50195, RMSE = 35.13054, MAPE = 9.57885
Step 10 MAE = 21.84547, RMSE = 35.66449, MAPE = 9.77065
Step 11 MAE = 22.21028, RMSE = 36.20153, MAPE = 9.98323
Step 12 MAE = 22.63468, RMSE = 36.74868, MAPE = 10.26849
Inference time: 57.35 s

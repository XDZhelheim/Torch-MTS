METRLA
Trainset:	x-(23974, 12, 207, 3)	y-(23974, 12, 207, 3)
Valset:  	x-(3425, 12, 207, 3)  	y-(3425, 12, 207, 3)
Testset:	x-(6850, 12, 207, 3)	y-(6850, 12, 207, 3)

Random seed = 233
--------- STDN ---------
{
    "num_nodes": 207,
    "in_steps": 12,
    "out_steps": 12,
    "time_of_day": true,
    "day_of_week": true,
    "y_time_of_day": true,
    "y_day_of_week": true,
    "runner": "STDN",
    "loss": "masked_mae",
    "pass_device": true,
    "lr": 0.001,
    "milestones": [
        10,
        30
    ],
    "clip_grad": 0,
    "batch_size": 64,
    "max_epochs": 200,
    "early_stop": 20,
    "model_args": {
        "num_of_vertices": 207,
        "adj_path": "../data/METRLA/adj_mx.pkl",
        "L": 2,
        "K": 16,
        "d": 8,
        "node_miss_rate": 0.1,
        "T_miss_len": 12,
        "order": 3,
        "reference": 3,
        "time_slice_size": 5,
        "num_his": 12,
        "num_pred": 12,
        "in_channels": 1,
        "out_channels": 1,
        "bn_decay": 0.1,
        "device": "cuda:0"
    }
}
=========================================================================================================
Layer (type:depth-idx)                                  Output Shape              Param #
=========================================================================================================
STDN                                                    [64, 12, 207, 1]          2,187,008
├─FC: 1-1                                               [64, 12, 207, 128]        --
│    └─ModuleList: 2-1                                  --                        --
│    │    └─conv2d_: 3-1                                [64, 12, 207, 128]        512
│    │    └─conv2d_: 3-2                                [64, 12, 207, 128]        16,768
├─gcn: 1-2                                              [64, 12, 207, 128]        --
│    └─nconv: 2-2                                       [64, 128, 207, 12]        --
│    └─nconv: 2-3                                       [64, 128, 207, 12]        --
│    └─nconv: 2-4                                       [64, 128, 207, 12]        --
│    └─FC: 2-5                                          [64, 12, 207, 128]        --
│    │    └─ModuleList: 3-3                             --                        65,920
├─SEmbedding: 1-3                                       [64, 12, 207, 128]        --
│    └─Linear: 2-6                                      [207, 32]                 1,056
│    └─LayerNorm: 2-7                                   [207, 32]                 --
│    └─LeakyReLU: 2-8                                   [207, 32]                 --
│    └─Linear: 2-9                                      [207, 128]                4,224
│    └─LayerNorm: 2-10                                  [207, 128]                --
├─TEmbedding: 1-4                                       [64, 12, 207, 128]        --
│    └─FC: 2-11                                         [64, 24, 207, 128]        --
│    │    └─ModuleList: 3-4                             --                        71,680
├─Trend: 1-5                                            [64, 12, 207, 128]        --
├─Seasonal: 1-6                                         [64, 12, 207, 128]        --
├─FeedForward: 1-7                                      [64, 12, 207, 128]        --
│    └─ModuleList: 2-12                                 --                        --
│    │    └─Linear: 3-5                                 [64, 12, 207, 128]        16,512
│    └─LayerNorm: 2-13                                  [64, 12, 207, 128]        --
├─FeedForward: 1-8                                      [64, 12, 207, 128]        --
│    └─ModuleList: 2-14                                 --                        --
│    │    └─Linear: 3-6                                 [64, 12, 207, 128]        16,512
│    └─LayerNorm: 2-15                                  [64, 12, 207, 128]        --
├─GRUEncoder: 1-9                                       [64, 12, 207, 128]        --
│    └─ModuleList: 2-16                                 --                        --
│    │    └─GRU: 3-7                                    [64, 207, 128]            98,688
│    │    └─GRU: 3-8                                    [64, 207, 128]            98,688
│    │    └─GRU: 3-9                                    [64, 207, 128]            98,688
│    │    └─GRU: 3-10                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-11                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-12                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-13                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-14                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-15                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-16                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-17                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-18                                   [64, 207, 128]            98,688
├─GRUEncoder: 1-10                                      [64, 12, 207, 128]        --
│    └─ModuleList: 2-17                                 --                        --
│    │    └─GRU: 3-19                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-20                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-21                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-22                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-23                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-24                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-25                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-26                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-27                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-28                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-29                                   [64, 207, 128]            98,688
│    │    └─GRU: 3-30                                   [64, 207, 128]            98,688
├─ModuleList: 1-11                                      --                        --
│    └─AttentionDecoder: 2-18                           [64, 12, 207, 128]        238,464
│    │    └─MAB_new: 3-31                               [64, 3, 207, 384]         198,912
│    │    └─MAB_new: 3-32                               [64, 12, 207, 128]        165,376
│    └─AttentionDecoder: 2-19                           [64, 12, 207, 128]        238,464
│    │    └─MAB_new: 3-33                               [64, 3, 207, 384]         198,912
│    │    └─MAB_new: 3-34                               [64, 12, 207, 128]        165,376
├─FC: 1-12                                              [64, 12, 207, 1]          --
│    └─ModuleList: 2-20                                 --                        --
│    │    └─conv2d_: 3-35                               [64, 12, 207, 128]        16,768
│    │    └─conv2d_: 3-36                               [64, 12, 207, 1]          131
=========================================================================================================
Total params: 5,971,107
Trainable params: 5,971,107
Non-trainable params: 0
Total mult-adds (G): 106.40
=========================================================================================================
Input size (MB): 3.18
Forward/backward pass size (MB): 8142.38
Params size (MB): 13.23
Estimated Total Size (MB): 8158.79
=========================================================================================================

Loss: MaskedMAELoss

2025-02-19 09:52:16.002744 Epoch 1  	Train Loss = 3.92828 Val Loss = 3.82123
2025-02-19 09:54:14.463351 Epoch 2  	Train Loss = 3.22375 Val Loss = 3.31195
2025-02-19 09:56:13.159543 Epoch 3  	Train Loss = 3.10156 Val Loss = 3.06213
2025-02-19 09:58:11.961864 Epoch 4  	Train Loss = 3.06803 Val Loss = 3.05995
2025-02-19 10:00:10.602087 Epoch 5  	Train Loss = 2.98999 Val Loss = 2.97160
2025-02-19 10:02:09.065538 Epoch 6  	Train Loss = 2.97053 Val Loss = 3.03017
2025-02-19 10:04:07.377872 Epoch 7  	Train Loss = 2.94925 Val Loss = 2.99725
2025-02-19 10:06:05.648182 Epoch 8  	Train Loss = 2.92341 Val Loss = 3.04523
2025-02-19 10:08:04.408777 Epoch 9  	Train Loss = 2.90450 Val Loss = 3.07232
2025-02-19 10:10:02.993890 Epoch 10  	Train Loss = 2.89300 Val Loss = 2.95809
2025-02-19 10:12:01.872539 Epoch 11  	Train Loss = 2.82716 Val Loss = 2.96846
2025-02-19 10:14:00.998012 Epoch 12  	Train Loss = 2.80808 Val Loss = 2.93261
2025-02-19 10:15:59.618216 Epoch 13  	Train Loss = 2.80146 Val Loss = 2.94871
2025-02-19 10:17:57.975554 Epoch 14  	Train Loss = 2.79413 Val Loss = 3.00276
2025-02-19 10:19:56.333522 Epoch 15  	Train Loss = 2.78699 Val Loss = 3.06315
2025-02-19 10:21:55.168805 Epoch 16  	Train Loss = 2.78093 Val Loss = 3.01183
2025-02-19 10:23:53.962286 Epoch 17  	Train Loss = 2.77693 Val Loss = 3.00210
2025-02-19 10:25:52.185153 Epoch 18  	Train Loss = 2.77179 Val Loss = 2.97678
2025-02-19 10:27:50.765340 Epoch 19  	Train Loss = 2.77099 Val Loss = 2.99877
2025-02-19 10:29:49.410762 Epoch 20  	Train Loss = 2.76828 Val Loss = 2.96467
2025-02-19 10:31:47.856428 Epoch 21  	Train Loss = 2.75957 Val Loss = 2.99725
2025-02-19 10:33:46.769104 Epoch 22  	Train Loss = 2.75558 Val Loss = 3.03044
2025-02-19 10:35:45.737207 Epoch 23  	Train Loss = 2.75044 Val Loss = 3.01250
2025-02-19 10:37:44.288498 Epoch 24  	Train Loss = 2.74746 Val Loss = 2.97178
2025-02-19 10:39:42.994547 Epoch 25  	Train Loss = 2.74606 Val Loss = 2.98434
2025-02-19 10:41:41.836767 Epoch 26  	Train Loss = 2.73998 Val Loss = 2.96345
2025-02-19 10:43:40.531198 Epoch 27  	Train Loss = 2.73467 Val Loss = 3.03542
2025-02-19 10:45:39.161511 Epoch 28  	Train Loss = 2.73299 Val Loss = 2.98409
2025-02-19 10:47:37.712233 Epoch 29  	Train Loss = 2.72555 Val Loss = 3.04453
2025-02-19 10:49:36.005650 Epoch 30  	Train Loss = 2.72282 Val Loss = 3.00120
2025-02-19 10:51:34.919626 Epoch 31  	Train Loss = 2.70906 Val Loss = 2.99672
2025-02-19 10:53:33.929654 Epoch 32  	Train Loss = 2.70411 Val Loss = 3.00614
Early stopping at epoch: 32
Best at epoch 12:
Train Loss = 2.80808
Train MAE = 2.76318, RMSE = 5.71829, MAPE = 7.52229
Val Loss = 2.93261
Val MAE = 2.96389, RMSE = 6.51143, MAPE = 8.54284
Model checkpoint saved to: ../saved_models/STDN/STDN-METRLA-2025-02-19-09-50-13.pt
--------- Test ---------
All Steps (1-12) MAE = 3.14720, RMSE = 6.78092, MAPE = 9.16724
Step 1 MAE = 2.33821, RMSE = 4.31101, MAPE = 5.90368
Step 2 MAE = 2.62961, RMSE = 5.21437, MAPE = 6.96999
Step 3 MAE = 2.83204, RMSE = 5.83790, MAPE = 7.77614
Step 4 MAE = 2.98543, RMSE = 6.30007, MAPE = 8.41882
Step 5 MAE = 3.10455, RMSE = 6.63775, MAPE = 8.95123
Step 6 MAE = 3.20583, RMSE = 6.92215, MAPE = 9.39990
Step 7 MAE = 3.28780, RMSE = 7.13823, MAPE = 9.75290
Step 8 MAE = 3.36271, RMSE = 7.34108, MAPE = 10.08581
Step 9 MAE = 3.42841, RMSE = 7.50116, MAPE = 10.36445
Step 10 MAE = 3.48448, RMSE = 7.64271, MAPE = 10.59613
Step 11 MAE = 3.53353, RMSE = 7.73722, MAPE = 10.81036
Step 12 MAE = 3.57383, RMSE = 7.80140, MAPE = 10.97756
Inference time: 10.39 s
